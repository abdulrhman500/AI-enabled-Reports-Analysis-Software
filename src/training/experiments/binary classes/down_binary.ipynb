{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original class distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def plot_class_distribution(list_,labels,message = \"Original Class Distribution\"):\n",
    "    unique, counts = np.unique(list_, return_counts=True)\n",
    "    colors =['green','yellow']\n",
    "    if len(unique) == 3 :\n",
    "        colors.append('red')\n",
    "        \n",
    "    plt.bar(unique, counts, color=colors)\n",
    "    plt.title(message)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_class_distribution_pie(list_, labels, message=\"Original Class Distribution\"):\n",
    "    unique, counts = np.unique(list_, return_counts=True)\n",
    "    plt.pie(counts, labels=labels, colors=['green','yellow', 'red'], autopct='%1.1f%%')\n",
    "    plt.title(message)\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def read_csv_data(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    names = data['name'].tolist()\n",
    "    labels = data['label'].tolist()\n",
    "    texts = data['text'].tolist()\n",
    "    return names, labels, texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_uinque_labels(labels):\n",
    "    unique = [0,0,0]\n",
    "    for label in labels:\n",
    "        if label.lower() =='approved':\n",
    "            unique[0] += 1\n",
    "        elif label.lower() == 'reject':\n",
    "            unique[1] += 1\n",
    "        else:\n",
    "            unique[2] += 1        \n",
    "    return {'approved':unique[0],'reject':unique[1],'pending':unique[2]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'approved': 198, 'reject': 8, 'pending': 30}\n"
     ]
    }
   ],
   "source": [
    "csv_file = 'Dataset.csv'\n",
    "names, labels, texts = read_csv_data(csv_file)\n",
    "\n",
    "print(count_uinque_labels(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data import Data\n",
    "\n",
    "def addToData1(names, labels, texts, data_obj, vectorization_technique):\n",
    "    for name, label, text in zip(names, labels, texts):\n",
    "        vector = vectorization_technique(text.strip()).numpy().tolist()\n",
    "        data_obj.add_data(name.strip(), vector, label.strip())\n",
    "    return data_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Data.Data at 0x1f19b942650>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from USE import apply_USE \n",
    "obj = Data()\n",
    "addToData1(names, labels, texts, obj, apply_USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number:  236\n",
      "{'approved': 198, 'reject': 38, 'pending': 0}\n"
     ]
    }
   ],
   "source": [
    "X = obj.get_column(obj.col_document_vector)\n",
    "y = obj.get_column(obj.col_decision)\n",
    "print(\"Total number: \",len(X))\n",
    "# set pending to reject\n",
    "for i in range(len(y)):\n",
    "    if y[i] == 'Pending':\n",
    "        y[i]='Reject'  \n",
    "labels_count = count_uinque_labels(y)        \n",
    "print(labels_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "approvals = labels_count['approved']\n",
    "rejects = labels_count['reject']\n",
    "pending = labels_count['pending']\n",
    "down_ration = 2/6\n",
    "downsample_class_proportions = {'Approved':int(approvals*down_ration), 'Reject':rejects }\n",
    "downsample_class_proportions='auto'\n",
    "rus = RandomUnderSampler(random_state=42,sampling_strategy=downsample_class_proportions)\n",
    "\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Resampling:  Counter({'Approved': 198, 'Reject': 38})\n",
      "After Resampling:  Counter({'Approved': 38, 'Reject': 38})\n"
     ]
    }
   ],
   "source": [
    "# original_labels = y\n",
    "# resampled_labels = y_resampled\n",
    "# plot_class_distribution_pie(original_labels, labels=['approved', 'pending','rejected'], message=\"Original Class Distribution\")\n",
    "# plot_class_distribution_pie(resampled_labels, labels=['approved', 'pending','rejected'], message=\"Resampled Class Distribution\")\n",
    "\n",
    "# plot_class_distribution(original_labels, labels=['Class 0', 'Class 1'], message=\"Original Class Distribution\")\n",
    "# plot_class_distribution(resampled_labels, labels=['Class 0', 'Class 1'], message=\"Resampled Class Distribution\")\n",
    "print(\"Before Resampling: \",Counter(y))\n",
    "print(\"After Resampling: \",Counter(y_resampled))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  Counter({'Approved': 8, 'Reject': 8})\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtest: \u001b[39m\u001b[39m\"\u001b[39m,Counter(y_test))\n\u001b[1;32m----> 8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtrain: \u001b[39m\u001b[39m\"\u001b[39m,Counter(X_train))\n",
      "File \u001b[1;32mc:\\Users\\Abdulrhman Fahmy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\collections\\__init__.py:597\u001b[0m, in \u001b[0;36mCounter.__init__\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''Create a new, empty Counter object.  And if given, count elements\u001b[39;00m\n\u001b[0;32m    587\u001b[0m \u001b[39mfrom an input iterable.  Or, initialize the count from another mapping\u001b[39;00m\n\u001b[0;32m    588\u001b[0m \u001b[39mof elements to their counts.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    594\u001b[0m \n\u001b[0;32m    595\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    596\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m--> 597\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(iterable, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[1;32mc:\\Users\\Abdulrhman Fahmy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\collections\\__init__.py:688\u001b[0m, in \u001b[0;36mCounter.update\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    686\u001b[0m             \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mupdate(iterable)\n\u001b[0;32m    687\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 688\u001b[0m         _count_elements(\u001b[39mself\u001b[39;49m, iterable)\n\u001b[0;32m    689\u001b[0m \u001b[39mif\u001b[39;00m kwds:\n\u001b[0;32m    690\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(kwds)\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"test: \",Counter(y_test))\n",
    "print(\"train: \",Counter(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Approved       0.83      0.62      0.71         8\n",
      "      Reject       0.70      0.88      0.78         8\n",
      "\n",
      "    accuracy                           0.75        16\n",
      "   macro avg       0.77      0.75      0.75        16\n",
      "weighted avg       0.77      0.75      0.75        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
