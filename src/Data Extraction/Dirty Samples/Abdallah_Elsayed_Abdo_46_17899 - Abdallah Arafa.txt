Activities:
In this internship. I was trying to research and apply dif ferent techniques of combining dif ferent
trained models to improve their performance metric. I did my research on two tasks: the first was
Speech Recognition and the second was Neural Machine Translation. This task was an individual
task however , I was supervised by two mentors: Andrew Baher for Speech Recognition and
Evram Narrouz for Neural Machine Translation. I was working five days per week for 8 hours
every day . I could either work from home or go work at the company and I chose to go to the
company once or twice a week. My typical working day started with having a meeting with
either one of my supervisors that I was supposed to work on his task to plan the day and what I
am supposed to do for the day . Most of the time, I was performing experiments by training
models with dif ferent hyperparameters. While waiting for the models to finish training, I used to
read articles on new ways to average these models or new techniques to come up with new
experiments to perform. After training the models, I ran the average models code that I have
prepared for the experiment and when the results are ready , I communicate them to my
supervisor in order to discuss their gains and whether they were significant or not. Then, we
discuss the implications of our findings and propose new ideas to experiment. The tools that I
have used are dif ferent between the two tasks however , Python was the main language that I used
to code with, azure storage was the main database that stored all the models and datasets, and
amlt was the main platform to train the dif ferent models on it. The timeline of the internship
went as follows: I first started by reading dif ferent papers about model averaging and discussed
them with my supervisor until we decided that we should start working with one of them. In
order to execute that method, we had to train 16 dif ferent models so I was asked to write the
configuration files for training speech recognition models with dif ferent hyperparameters and
submitting them to training on Azure itp cluster machines. While waiting for them to finish
training I was supposed to design the algorithm for averaging them. I was supposed to do that on
a program called AEther for multiprocessing, but there was a problem that AEther could not give
feedback in the same module for each step so I had to write the code from scratch and that’ s what
I did. I spent almost 2-3 weeks writing the code for averaging and integrating it with the code
base of Microsoft for evaluating their speech recognition models. After getting the first results
from the speech recognition experiment, we decided that I should do the same with the NMT
task and embed my averaging code with TorchSpeech modules and this took me another two
weeks. This took me a total of six weeks to run one experiment on each task and I had 2 weeks
left for my internship. That’ s when my supervisors asked  me to extend my internship to continue
my experiments on the two tasks. For the last 6 weeks, I started exploring with my supervisors
different ideas for each task, some of them included exploring lar ger datasets to see how much
gain the algorithm would have. I also explored the custom translators in NMT , where the model
trained on a domain specific dataset like Medicine did well on this dataset but it usually did wayworse on the basic English sentences so I was asked to try model averaging on this model to
balance between its performance on the domain specific dataset and the general one as well.
At the end of my internship, I managed to deliver the average models that usually did a little bit
better than the stand alone trained models. This applied on both tasks and on the dif ferent
datasets and domain specific tasks.
Internship 