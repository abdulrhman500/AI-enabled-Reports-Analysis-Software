{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import spacy\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "# folder_path = 'C:\\\\Users\\\\hoda2\\\\Documents\\\\NLP Internship\\\\Rejected&Pending_Extraction\\\\Rejected&Pending_Extraction\\\\Rejected'\n",
    "# file_list = glob.glob(folder_path + \"/*.txt\")\n",
    "# dir_list = os.listdir(folder_path)\n",
    "df = pd.read_csv(\"Dataset2 clean.csv\")\n",
    "df.head()\n",
    "# df.label.value_counts()\n",
    "# df['label_num']= df['label'].map({'Approved':1, 'Pending':0, 'Reject':-1})\n",
    "# df['vector'] = df['vector'].apply(lambda x: np.fromstring(x, sep=','))\n",
    "# df['vector'] = df['vector'].apply(lambda x: np.array(x.replace(\"]\",\"\")))\n",
    "# df['vector'] = df['vector'].apply(lambda x: np.array(x.split(\",\")))\n",
    "# df['vector'] = df['vector'].apply(lambda x: print(type((x))))\n",
    "\n",
    "\n",
    "# # # X_trian.to_numpy()\n",
    "# X_trian_2d = np.stack(X_trian)\n",
    "# print(X_trian_2d)\n",
    "# for vector in X_trian:\n",
    "#     vector.replace(\"'\",\"\")\n",
    "\n",
    "# print(type(X_trian[0]))\n",
    "# X_trian_2d.flatten()\n",
    "# numpy_array = np.fromstring(X_trian, dtype=float, sep='[')\n",
    "# print(X_trian_2d)\n",
    "# X_trian_2d = np.array([X_trian.tolist()])\n",
    "# X_trian_2d = X_trian_2d.astype(float)\n",
    "# print(X_trian_2d)\n",
    "# X_test_2d = np.stack(X_test)\n",
    "# type(df.vector)\n",
    "# X_trian_2d = np.array([X_trian.tolist()])\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# type(X_trian)\n",
    "# scaled_train_embed = scaler.fit_transform(X_trian_2d)\n",
    "# scaled_test_embed = scaler.transform(X_test_2d)\n",
    "# print(X_test_2d)\n",
    "# clf = MultinomialNB()\n",
    "# clf.fit(scaled_train_embed,y_train)\n",
    "\n",
    "# out = pd.DataFrame({'name':[],'label':[],'text':[]})\n",
    "# for i in range(0,len(file_list)):\n",
    "#     with open(file_list[i], 'r', encoding='latin-1') as f:\n",
    "#       text = f.read().replace('\\n', '')\n",
    "#       new_row = {'name':file_list[i],'label':'Reject','text':text}\n",
    "#     out = pd.concat([out, pd.DataFrame([new_row])], ignore_index=True)\n",
    "#     # output = output.append(new_row, ignore_index=True)\n",
    "df['vector'] = df['text'].apply(lambda x: nlp(x).vector)\n",
    "# out['vector'] = out['vector'].apply(lambda x: print(type(x)))\n",
    "\n",
    "df.head()\n",
    "# final = pd.concat([df, out], ignore_index=True)\n",
    "df.to_csv('Dataset2 clean.csv', index=False)\n",
    "# output.shape\n",
    "# print(output.size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
