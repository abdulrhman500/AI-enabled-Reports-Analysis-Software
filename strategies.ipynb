{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Down Sampling + Binary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Label Counts:\n",
      " Approved    198\n",
      "Pending      30\n",
      "Reject        8\n",
      "Name: count, dtype: int64\n",
      "Undersampled Label Counts:\n",
      " 1    60\n",
      "0    30\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 0.8333333333333334\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.12      0.20         8\n",
      "           1       0.85      0.97      0.91        40\n",
      "\n",
      "    accuracy                           0.83        48\n",
      "   macro avg       0.67      0.55      0.55        48\n",
      "weighted avg       0.79      0.83      0.79        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import ast\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file_path = \"C:\\\\Users\\\\DELL\\\\Desktop\\\\USE\\\\AI-enabled-Reports-Analysis-Software\\\\Dataset.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df['Embedding'] = df['Embedding'].apply(ast.literal_eval)\n",
    "\n",
    "X = df['Embedding'].tolist()\n",
    "y = df['label'].tolist()\n",
    "\n",
    "# Calculate the count of \"1\" and \"0\" labels in the original dataset\n",
    "original_counts = pd.Series(y).value_counts()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\n",
    "\n",
    "# Convert \"Approved\" class to 1, and others to 0\n",
    "y_train_binary = ['1' if label == 'Approved' else '0' for label in y_train]\n",
    "\n",
    "# Apply undersampling to the \"Approved\" class in the training data\n",
    "undersampler = RandomUnderSampler(sampling_strategy={'1': 60})\n",
    "X_train_final, y_train_final = undersampler.fit_resample(X_train, y_train_binary)\n",
    "\n",
    "# Calculate the count of \"1\" and \"0\" labels in the undersampled dataset\n",
    "undersampled_counts = pd.Series(y_train_final).value_counts()\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_final, y_train_final)\n",
    "\n",
    "# Convert back to original labels for prediction\n",
    "y_test_binary = ['1' if label == 'Approved' else '0' for label in y_test]\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_binary, y_pred)\n",
    "classification_rep = classification_report(y_test_binary, y_pred)\n",
    "\n",
    "print(\"Original Label Counts:\\n\", original_counts)\n",
    "print(\"Undersampled Label Counts:\\n\", undersampled_counts)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DownSampling + Multinomial**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Approved       0.84      0.97      0.90        39\n",
      "     Pending       0.67      0.29      0.40         7\n",
      "      Reject       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.83        48\n",
      "   macro avg       0.50      0.42      0.43        48\n",
      "weighted avg       0.78      0.83      0.79        48\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import ast\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file_path = \"C:\\\\Users\\\\DELL\\\\Desktop\\\\USE\\\\AI-enabled-Reports-Analysis-Software\\\\Dataset.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df['Embedding'] = df['Embedding'].apply(ast.literal_eval)\n",
    "\n",
    "X = df['Embedding'].tolist()\n",
    "y = df['label'].tolist()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply undersampling only to the \"Approved\" class in the training data\n",
    "undersampler = RandomUnderSampler(sampling_strategy={'Approved': 50})\n",
    "X_train_final, y_train_final = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1300)\n",
    "model.fit(X_train_final, y_train_final)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UpSampling + Binary** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8541666666666666\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.33      0.46         9\n",
      "           1       0.86      0.97      0.92        39\n",
      "\n",
      "    accuracy                           0.85        48\n",
      "   macro avg       0.81      0.65      0.69        48\n",
      "weighted avg       0.84      0.85      0.83        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import ast\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file_path = \"C:\\\\Users\\\\DELL\\\\Desktop\\\\USE\\\\AI-enabled-Reports-Analysis-Software\\\\Dataset.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df['Embedding'] = df['Embedding'].apply(ast.literal_eval)\n",
    "\n",
    "X = df['Embedding'].tolist()\n",
    "y = df['label'].tolist()\n",
    "\n",
    "# Combine 'Pending' and 'Reject' labels into one class (0), and keep 'Approve' as another class (1)\n",
    "y_binary = [0 if label in ['Reject', 'Pending'] else 1 for label in y]\n",
    "\n",
    "# Split the original data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE oversampling to the 'Pending' and 'Reject' class in the training data only\n",
    "oversampler = SMOTE(sampling_strategy={0: 90})\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a logistic regression model for binary classification\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1300)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
