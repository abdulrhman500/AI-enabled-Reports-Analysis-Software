Tasks:  For the first task, it is about having to get a bank dataset and predict if the customer will leave or stay in the bank based on the previous recorded data. It required to describe data, then preprocessing it, then visualize it, then train model, evaluation and testing. So, I solved the task by getting a dataset with customers data in bank (age, has card or not, is current in bank or not) and the features of the customers then get profile report to get all characteristics of the data then get the statistics of every variable then get the correlation between every variable with each other to see if they affect the output so that if 2 independent variables have same importance on target then we drop one of them, in correlation, the ones that have most impact have a value closest to 1. Then afterwards obtain the missing values of the dataset then see if there is any duplicates in the dataset so I obtain the max number of duplicates which results in 0 then check if there is any null values. Afterwards unused columns are dropped as they are features that have no significance in correlation. Then visualize data by having the variable compare to each other in Histogram and Pie Chart then preprocess the data by changing value in variables from character to number (like true/false , Male/Female,...etc. to 1/0) where it changed every country into having its own column and if customer is in it then it's value there will be 1 and all 4 Student Career & Alumni Development Office. scad@guc.edu.eg | German University in Cairo New Cairo City - Main Entrance Al Tagamoa Al Khames; Egypt        other will be 0.Afterwards I train the model by train-test-split on an element so that we can test model on a separate data that model hasn't seen. Using columns not to values 0 or 1s  to show normal distribution, then balance data by class weight by having a small part of data have a high importance weight and have model be Sequential and have gradient decent with the reason to have better testing for the output and decrease error. Finally, we test model and get the prediction and record the accuracy, prediction and recall then draw the RDC graph.  For the second Task, it was to get all ATMs of Banque Misr and display them in a dashboard. I worked in a team where we got the data of all Bank Misr ATMs by web scrapping using Instant Data Scraper (chrome extension)the About Us page in Bank Misr where it hosted the locations of the ATMs then we exported them into excel where it had the entire address in google map URL format with the Latitude and Longitude then we checked if the data is accurate on the google map. Then we separated the Latitude and Longitude from the URL and put them in separate columns by using Text to column in Excel. Then by using Python, and importing the required libraries(geopandas) and excel sheet, after that we read the shape files by using the geopandas, then check for null values to drop then we plot the polygon in shapefile in a geometry then we find the polygon that contains each point then we put them into a list with the names of the columns that we will use, then we check the points inside the geometry with that of the polygon , and if it matches ,we put the data in the suitable list and if it doesn't match , null is putted onto the list with their index in a variable to be dropped afterwards. Then we put values in the list into columns then we export the data into an excel sheet to be used as in a dashboard which we used PowerBI to visualize and display the Dashboard where we imported the final excel sheet into PowerBI then having filters and slices to separate the data and putting it on a map to display and visualize the ATMs of Banque Misr in Egypt.  For the third task, It was a task to get the closest ATM for every specific ATM and show it on a dashboard , using the sheet from task2 and a formula taken from the internet (Haversine formula) , me and my team were able to get for each ATM the closest and 2nd closest and 3rd closest ATM by getting the distance in KM then sorting it then only taking the least 3 distances corresponding ATM then we turn the distances into meters and put them into columns then export it into excel. Afterward we showed and visualized the data in a dashboard using PowerBI where we imported the excel sheet into then separating the data by filters and slices then putting it on a main map to display all ATMs then we made another map to display the ATM that is closest to the ATM on the main map then we made a 3rd map to display the ATM that is the 2nd closest to the ATM on the main map with labels of their distance.    Internship 